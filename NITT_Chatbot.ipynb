{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eKrKINV-hlD0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Remove special characters and punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespaces\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "metadata": {
        "id": "CfmSnKIXAEAm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5Yl1jUvXhviT"
      },
      "outputs": [],
      "source": [
        "with open('/content/chatbot.json') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        cleaned_pattern = clean_text(pattern)\n",
        "        training_sentences.append(pattern)\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses.append(intent['responses'])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "\n",
        "num_classes = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3F-PVTC-h_q9"
      },
      "outputs": [],
      "source": [
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels = lbl_encoder.transform(training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QOgV-_arp48z"
      },
      "outputs": [],
      "source": [
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_len = 20\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "augmented_sentences = []\n",
        "augmented_labels = []\n",
        "\n",
        "for sequence, label in zip(padded_sequences, training_labels):\n",
        "    augmented_sentences.append(sequence)\n",
        "    augmented_labels.append(label)\n",
        "\n",
        "    # Shuffle words in the sentence\n",
        "    import random\n",
        "    words = sequence.tolist()\n",
        "    random.shuffle(words)\n",
        "    augmented_sentences.append(np.array(words))\n",
        "    augmented_labels.append(label)\n",
        "\n",
        "    # Add noise to the sequence\n",
        "    noise = np.random.normal(0, 0.05, sequence.shape)\n",
        "    noisy_sequence = sequence + noise\n",
        "    augmented_sentences.append(noisy_sequence)\n",
        "    augmented_labels.append(label)\n",
        ""
      ],
      "metadata": {
        "id": "2VEiHHbM9PmG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AUOxjoFXM7JH"
      },
      "outputs": [],
      "source": [
        "# Combine original and augmented data\n",
        "padded_sequences = np.vstack((padded_sequences, np.array(augmented_sentences)))\n",
        "training_labels = np.concatenate((training_labels, np.array(augmented_labels)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fML-j-JCNFz9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, training_labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PPoi9lFsp_T-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe2ea2bf-3250-4b6c-d9c1-cefd6dfd6b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 20, 16)            16000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 20, 64)            20736     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 17)                289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 71089 (277.69 KB)\n",
            "Trainable params: 71089 (277.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AP8Yn8JCqCiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f61b1bd-1d93-402e-e20f-113f57823f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "53/53 [==============================] - 8s 63ms/step - loss: 2.7835 - accuracy: 0.0925 - val_loss: 2.6556 - val_accuracy: 0.1161\n",
            "Epoch 2/15\n",
            "53/53 [==============================] - 2s 42ms/step - loss: 2.4852 - accuracy: 0.1495 - val_loss: 2.3654 - val_accuracy: 0.2133\n",
            "Epoch 3/15\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 2.2702 - accuracy: 0.2052 - val_loss: 2.1894 - val_accuracy: 0.2701\n",
            "Epoch 4/15\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 2.0749 - accuracy: 0.2633 - val_loss: 2.0349 - val_accuracy: 0.2820\n",
            "Epoch 5/15\n",
            "53/53 [==============================] - 2s 31ms/step - loss: 1.8796 - accuracy: 0.3084 - val_loss: 1.8919 - val_accuracy: 0.2938\n",
            "Epoch 6/15\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1.7332 - accuracy: 0.3808 - val_loss: 1.8437 - val_accuracy: 0.3412\n",
            "Epoch 7/15\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 1.5355 - accuracy: 0.4573 - val_loss: 1.6788 - val_accuracy: 0.4289\n",
            "Epoch 8/15\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 1.4108 - accuracy: 0.5095 - val_loss: 1.5077 - val_accuracy: 0.4692\n",
            "Epoch 9/15\n",
            "53/53 [==============================] - 2s 43ms/step - loss: 1.2485 - accuracy: 0.5741 - val_loss: 1.3881 - val_accuracy: 0.5166\n",
            "Epoch 10/15\n",
            "53/53 [==============================] - 2s 45ms/step - loss: 1.1442 - accuracy: 0.6026 - val_loss: 1.2676 - val_accuracy: 0.6161\n",
            "Epoch 11/15\n",
            "53/53 [==============================] - 2s 30ms/step - loss: 0.9996 - accuracy: 0.6708 - val_loss: 1.2090 - val_accuracy: 0.6090\n",
            "Epoch 12/15\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 0.9019 - accuracy: 0.6987 - val_loss: 1.1168 - val_accuracy: 0.6825\n",
            "Epoch 13/15\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 0.7939 - accuracy: 0.7325 - val_loss: 1.0655 - val_accuracy: 0.7014\n",
            "Epoch 14/15\n",
            "53/53 [==============================] - 2s 28ms/step - loss: 0.7350 - accuracy: 0.7663 - val_loss: 0.9461 - val_accuracy: 0.7322\n",
            "Epoch 15/15\n",
            "53/53 [==============================] - 2s 29ms/step - loss: 0.6587 - accuracy: 0.8084 - val_loss: 0.9356 - val_accuracy: 0.7630\n"
          ]
        }
      ],
      "source": [
        "\n",
        "epochs = 15\n",
        "history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORT22SSLqG4T",
        "outputId": "c0cf1bd2-ed2c-431a-bf0a-e4ce709ba07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: hi\n",
            "1/1 [==============================] - 1s 828ms/step\n",
            "Chatbot: Hey there, how can I make your interaction with NIT-Trichy more productive?\n",
            "You: pragyan\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Chatbot: Pragyan is NIT Trichy's annual techno-managerial festival, typically conducted during the even semester. It showcases a diverse range of technical, managerial, and cultural events, attracting participants from all over the country. Pragyan aims to provide a platform for students to showcase their talents, learn from experts, and engage in various enriching activities. For the latest updates and detailed information about Pragyan, you can visit the official Pragyan website or page.\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    # Preprocess the user input\n",
        "    cleaned_user_input = clean_text(user_input)\n",
        "    user_input_sequence = tokenizer.texts_to_sequences([user_input])\n",
        "    user_input_padded = pad_sequences(user_input_sequence, truncating='post', maxlen=max_len)\n",
        "\n",
        "    # Get the model's prediction\n",
        "    prediction = model.predict(user_input_padded)\n",
        "    predicted_label = lbl_encoder.inverse_transform([np.argmax(prediction)])\n",
        "\n",
        "    # Find the appropriate response\n",
        "    for intent in data['intents']:\n",
        "        if intent['tag'] == predicted_label:\n",
        "            response = np.random.choice(intent['responses'])\n",
        "            print(\"Chatbot:\", response)\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hd_bPOUyqkLc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WLY0-ApnMSOi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}